\chapter{Conclusiones}
\doublespacing

\begin{enumerate}
	\item Se aplicaron con éxito técnicas de deep learning para clasificar y segmentar cuerpos glaciares a nivel de píxel en imágenes multiespectrales. Los modelos utilizados mostraron un rendimiento eficaz en la clasificación y segmentación de estos cuerpos, logrando resultados precisos. Sin embargo, fue necesario seleccionar el modelo de aprendizaje profundo con mejor desempeño, y se eligió U-Net por los resultados sobresalientes que presentó.
	
	El análisis se realizó con imágenes del glaciar Quelccaya tomadas entre 1991 y noviembre de 2024. Para asegurar la precisión, se seleccionaron manualmente imágenes libres de nieve temporal y nubes, evitando así resultados falsos. Hubo algunos años en los que no se encontraron imágenes adecuadas, pero se incluyeron todas las disponibles para analizar y evaluar la estimación de la superficie glaciar de Quelccaya.
	
	A partir de este conjunto de datos, se efectuó un análisis temporal que muestra una clara disminución en la extensión del glaciar a lo largo de las décadas. Sin embargo, se observaron algunos años en los que la superficie glaciar aumentó ligeramente, probablemente debido a la presencia mínima de nieve temporal o a variaciones meteorológicas. Este patrón de incremento también aparece en otros estudios con los que se compararon los resultados.
	
	Finalmente, el método de segmentación mediante modelos de deep learning y el análisis temporal del retroceso de la superficie glaciar fueron llevados a cabo satisfactoriamente.
	
	\item Se utilizaron modelos basados en redes neuronales convolucionales (CNN) para la segmentación semántica de cuerpos glaciares, empleando tres arquitecturas: U-Net, DeepResUNet y DeepLabV3Plus. Los tres modelos demostraron ser efectivos en la tarea de segmentación, gracias a sus arquitecturas encoder-decoder, que permiten aprender características relevantes de los glaciares de manera automática. En comparación con los métodos tradicionales como el índice NDSI, que a menudo es lento y generalmente brinda resultados inapropiados al calcular incorrectamente el agua como nieve, los modelos de deep learning presentaron mejores resultados, con U-Net destacándose por su alta precisión. Las métricas obtenidas con U-Net fueron sobresalientes, con un MIoU de 0.9810, PA de 0.9979, Dice Coefficient de 0.9904 y un Loss de 0.01. Esto valida la hipótesis de que los algoritmos de deep learning pueden ofrecer una precisión significativa en la segmentación de cuerpos glaciares. Además, se sugiere que incluir más variables relevantes, como factores climáticos o topográficos, podría mejorar aún más el rendimiento del modelo.
	
	\item Se logró desarrollar una base de datos confiable de 2400 imágenes satelitales, con una distribución de datos del 70\% para entrenamiento, 15\% para validación y 15\% para testeo. Para garantizar la calidad de los datos, se seleccionaron cuidadosamente imágenes multiespectrales que contenían exclusivamente cuerpos glaciares, y se etiquetaron solo los píxeles correspondientes a características glaciares, estas etiquetas se pueden observar en la Figura \ref{fig:rgb_mascara}. Además, se utilizó Google Earth para verificar que los píxeles etiquetados realmente correspondieran a áreas glaciales. Con esta base de datos, los modelos de deep learning lograron una segmentación muy buena y efectiva de los cuerpos glaciares, tal como se puede observar en la Figura \ref{fig:comparative_predictions}, donde los tres modelos segmentan cuerpos glaciares con una alta precisión para clasificar pixeles con características glaciares, validando la hipótesis de que la creación de una base de datos adecuada contribuye al rendimiento de los modelos, aunque la magnitud de la precisión puede variar.
	
	\item Se analizaron los cambios en la superficie glaciar utilizando las imágenes segmentadas por el modelo U-Net y se cuantificó el área glaciar en diferentes años mediante un análisis temporal. Los resultados muestran que la extensión glaciar en 1991 era de 50.8131 km², mientras que en noviembre de 2024 se redujo a 35.4951 km², lo que representa una tasa de retroceso de aproximadamente 0.3936 km² por año. Sin embargo, en algunos años, las estimaciones mostraron un área mayor que la de años previos, lo que puede estar relacionado con la presencia de nieve temporal en las imágenes. Como se puede evidenciar en el año 2010, la estimación de área glaciar para este estudio fue de 40.0995 km² y para el año 2014 la estimación glaciar fue de 43.3746 km²; sin embargo, tal fenómeno también ocurrió con el análisis de \parencite{malone2022evolution}, quien en el año 2010 obtuvo 41.91 km2 y para el año 2014 obtuvo una estimación glaciar de 42.37 km².
	
	Para obtener estimaciones más precisas, es esencial evitar las imágenes que contengan nieve temporal, ya que esto puede introducir errores significativos en la medición. Se recomienda analizar múltiples imágenes durante la estación seca (junio-septiembre) y seleccionar aquellas con mínima presencia de nieve temporal. No obstante, incluso con estas precauciones, la estimación de la superficie glaciar puede seguir siendo incierta debido a las variaciones climáticas y las condiciones de cobertura en cada año. Además, algunos años no fueron considerados debido a la presencia excesiva de nieve temporal, nubosidad alta o la falta de imágenes disponibles en las fechas correspondientes.
	
	\item Los antecedentes sobre la estimación de la extensión del glaciar Quelcaya son limitados, y no se encontraron datos oficiales de instituciones gubernamentales. Sin embargo, se realizó una comparación de los resultados de superficie glaciar obtenidos en este estudio con los de artículos científicos, especialmente con el trabajo de \parencite{malone2022evolution}, \parencite{taylor2022multi} y \parencite{hanshaw2014glacial}. Los resultados del análisis temporal muestran una alta concordancia con los estudios previos, con estimaciones de superficie glaciar muy cercanas, como se observa en los años 1991, 1995, 1999, 2009, 2015, 2019 y 2020. En este estudio, las estimaciones de superficie glaciar fueron de 50.81, 48.71, 46.26, 41.41, 41.59, 38.42 y 38.99 km², mientras que \parencite{malone2022evolution} reportó valores de 50.89, 48.89, 46.44, 41.69, 41.65, 38.79 y 39.03 km² en los mismos años. Para los años 1991, 1992, 2006, 2016, 2019 . En este estudio, las estimaciones de superficie glaciar furon de 50.81, 49.45, 44.19, 39.25, 38.42 km², mientras que \parencite{taylor2022multi} reportó valores de 50.21, 49.08, 44.79, 40.57, 39.58 km². Para el año 2006 en este estudio, la estimación glaciar fue de 44.19 km², mientras que en \parencite{hanshaw2014glacial} reportó un valor de 44.4 km². Se puede concluir que muchos de los valores obtenidos en este estudio son muy proximos a los antecedentes mencionados, en general las estimaciones de superficie glaciar obtenidas en este estudio muestran que, los valores obtenidos son muy cercanos a los valores reportados por \parencite{malone2022evolution}, \parencite{taylor2022multi} y \parencite{hanshaw2014glacial}, lo que sugiere que los resultados obtenidos mediante aprendizaje profundo son comparables a los obtenidos con métodos tradicionales como el NDSI. 
	
	Es importante destacar que el método tradicional NDSI utilizado en los estudios previos y el método de segmentación semántica basado en deep learning empleado en este estudio son técnicamente diferentes. Sin embargo, esta comparación demuestra que el aprendizaje profundo puede ser una alternativa competitiva y precisa para la estimación de la superficie glaciar, ofreciendo resultados similares a los de métodos más tradicionales.
	
	
\end{enumerate}

\singlespacing