{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "#\n",
    "import PIL\n",
    "from PIL import Image\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_3_k(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=1, padding=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv1(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Double_Conv(nn.Module):\n",
    "    '''\n",
    "    Double convolution block for U-Net\n",
    "    '''\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "                           Conv_3_k(channels_in, channels_out),\n",
    "                           nn.BatchNorm2d(channels_out),\n",
    "                           nn.ReLU(),\n",
    "            \n",
    "                           Conv_3_k(channels_out, channels_out),\n",
    "                           nn.BatchNorm2d(channels_out),\n",
    "                           nn.ReLU(),\n",
    "                            )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down_Conv(nn.Module):\n",
    "    '''\n",
    "    Down convolution part\n",
    "    '''\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        Double_Conv(channels_in, channels_out)\n",
    "                        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "class Up_Conv(nn.Module):\n",
    "    '''\n",
    "    Up convolution part\n",
    "    '''\n",
    "    def __init__(self,channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.upsample_layer = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=2, mode='bicubic'),\n",
    "                        nn.Conv2d(channels_in, channels_in//2, kernel_size=1, stride=1)\n",
    "                        )\n",
    "        self.decoder = Double_Conv(channels_in, channels_out)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        '''\n",
    "        x1 - upsampled volume\n",
    "        x2 - volume from down sample to concatenate\n",
    "        '''\n",
    "        x1 = self.upsample_layer(x1)\n",
    "        x = torch.cat([x2, x1],dim=1)\n",
    "        return self.decoder(x)\n",
    "    \n",
    "class UNET(nn.Module):\n",
    "    '''\n",
    "    UNET model\n",
    "    '''\n",
    "    def __init__(self, channels_in, channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.first_conv = Double_Conv(channels_in, channels) #64, 224, 224\n",
    "        self.down_conv1 = Down_Conv(channels, 2*channels) # 128, 112, 112\n",
    "        self.down_conv2 = Down_Conv(2*channels, 4*channels) # 256, 56, 56\n",
    "        self.down_conv3 = Down_Conv(4*channels, 8*channels) # 512, 28, 28\n",
    "        \n",
    "        self.middle_conv = Down_Conv(8*channels, 16*channels) # 1024, 14, 14 \n",
    "        \n",
    "        self.up_conv1 = Up_Conv(16*channels, 8*channels)\n",
    "        self.up_conv2 = Up_Conv(8*channels, 4*channels)\n",
    "        self.up_conv3 = Up_Conv(4*channels, 2*channels)\n",
    "        self.up_conv4 = Up_Conv(2*channels, channels)\n",
    "        \n",
    "        self.last_conv = nn.Conv2d(channels, num_classes, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.first_conv(x)\n",
    "        x2 = self.down_conv1(x1)\n",
    "        x3 = self.down_conv2(x2)\n",
    "        x4 = self.down_conv3(x3)\n",
    "        \n",
    "        x5 = self.middle_conv(x4)\n",
    "        \n",
    "        u1 = self.up_conv1(x5, x4)\n",
    "        u2 = self.up_conv2(u1, x3)\n",
    "        u3 = self.up_conv3(u2, x2)\n",
    "        u4 = self.up_conv4(u3, x1)\n",
    "        \n",
    "        return self.last_conv(u4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (first_conv): Double_Conv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv_3_k(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv_3_k(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (down_conv1): Down_Conv(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Double_Conv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv_3_k(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv_3_k(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_conv2): Down_Conv(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Double_Conv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv_3_k(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv_3_k(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_conv3): Down_Conv(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Double_Conv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv_3_k(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv_3_k(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_conv): Down_Conv(\n",
       "    (encoder): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Double_Conv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv_3_k(\n",
       "            (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv_3_k(\n",
       "            (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv1): Up_Conv(\n",
       "    (upsample_layer): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bicubic')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (decoder): Double_Conv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv_3_k(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv_3_k(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv2): Up_Conv(\n",
       "    (upsample_layer): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bicubic')\n",
       "      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (decoder): Double_Conv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv_3_k(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv_3_k(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv3): Up_Conv(\n",
       "    (upsample_layer): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bicubic')\n",
       "      (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (decoder): Double_Conv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv_3_k(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv_3_k(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv4): Up_Conv(\n",
       "    (upsample_layer): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bicubic')\n",
       "      (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (decoder): Double_Conv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv_3_k(\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv_3_k(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (last_conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNET(3, 64, 2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "          Conv_3_k-2         [-1, 64, 256, 256]               0\n",
      "       BatchNorm2d-3         [-1, 64, 256, 256]             128\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "            Conv2d-5         [-1, 64, 256, 256]          36,928\n",
      "          Conv_3_k-6         [-1, 64, 256, 256]               0\n",
      "       BatchNorm2d-7         [-1, 64, 256, 256]             128\n",
      "              ReLU-8         [-1, 64, 256, 256]               0\n",
      "       Double_Conv-9         [-1, 64, 256, 256]               0\n",
      "        MaxPool2d-10         [-1, 64, 128, 128]               0\n",
      "           Conv2d-11        [-1, 128, 128, 128]          73,856\n",
      "         Conv_3_k-12        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
      "             ReLU-14        [-1, 128, 128, 128]               0\n",
      "           Conv2d-15        [-1, 128, 128, 128]         147,584\n",
      "         Conv_3_k-16        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-17        [-1, 128, 128, 128]             256\n",
      "             ReLU-18        [-1, 128, 128, 128]               0\n",
      "      Double_Conv-19        [-1, 128, 128, 128]               0\n",
      "        Down_Conv-20        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-21          [-1, 128, 64, 64]               0\n",
      "           Conv2d-22          [-1, 256, 64, 64]         295,168\n",
      "         Conv_3_k-23          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "           Conv2d-26          [-1, 256, 64, 64]         590,080\n",
      "         Conv_3_k-27          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-28          [-1, 256, 64, 64]             512\n",
      "             ReLU-29          [-1, 256, 64, 64]               0\n",
      "      Double_Conv-30          [-1, 256, 64, 64]               0\n",
      "        Down_Conv-31          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-32          [-1, 256, 32, 32]               0\n",
      "           Conv2d-33          [-1, 512, 32, 32]       1,180,160\n",
      "         Conv_3_k-34          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-35          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-36          [-1, 512, 32, 32]               0\n",
      "           Conv2d-37          [-1, 512, 32, 32]       2,359,808\n",
      "         Conv_3_k-38          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-39          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-40          [-1, 512, 32, 32]               0\n",
      "      Double_Conv-41          [-1, 512, 32, 32]               0\n",
      "        Down_Conv-42          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-43          [-1, 512, 16, 16]               0\n",
      "           Conv2d-44         [-1, 1024, 16, 16]       4,719,616\n",
      "         Conv_3_k-45         [-1, 1024, 16, 16]               0\n",
      "      BatchNorm2d-46         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-47         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-48         [-1, 1024, 16, 16]       9,438,208\n",
      "         Conv_3_k-49         [-1, 1024, 16, 16]               0\n",
      "      BatchNorm2d-50         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-51         [-1, 1024, 16, 16]               0\n",
      "      Double_Conv-52         [-1, 1024, 16, 16]               0\n",
      "        Down_Conv-53         [-1, 1024, 16, 16]               0\n",
      "         Upsample-54         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-55          [-1, 512, 32, 32]         524,800\n",
      "           Conv2d-56          [-1, 512, 32, 32]       4,719,104\n",
      "         Conv_3_k-57          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-58          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-59          [-1, 512, 32, 32]               0\n",
      "           Conv2d-60          [-1, 512, 32, 32]       2,359,808\n",
      "         Conv_3_k-61          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-62          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-63          [-1, 512, 32, 32]               0\n",
      "      Double_Conv-64          [-1, 512, 32, 32]               0\n",
      "          Up_Conv-65          [-1, 512, 32, 32]               0\n",
      "         Upsample-66          [-1, 512, 64, 64]               0\n",
      "           Conv2d-67          [-1, 256, 64, 64]         131,328\n",
      "           Conv2d-68          [-1, 256, 64, 64]       1,179,904\n",
      "         Conv_3_k-69          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-70          [-1, 256, 64, 64]             512\n",
      "             ReLU-71          [-1, 256, 64, 64]               0\n",
      "           Conv2d-72          [-1, 256, 64, 64]         590,080\n",
      "         Conv_3_k-73          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-74          [-1, 256, 64, 64]             512\n",
      "             ReLU-75          [-1, 256, 64, 64]               0\n",
      "      Double_Conv-76          [-1, 256, 64, 64]               0\n",
      "          Up_Conv-77          [-1, 256, 64, 64]               0\n",
      "         Upsample-78        [-1, 256, 128, 128]               0\n",
      "           Conv2d-79        [-1, 128, 128, 128]          32,896\n",
      "           Conv2d-80        [-1, 128, 128, 128]         295,040\n",
      "         Conv_3_k-81        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-82        [-1, 128, 128, 128]             256\n",
      "             ReLU-83        [-1, 128, 128, 128]               0\n",
      "           Conv2d-84        [-1, 128, 128, 128]         147,584\n",
      "         Conv_3_k-85        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-86        [-1, 128, 128, 128]             256\n",
      "             ReLU-87        [-1, 128, 128, 128]               0\n",
      "      Double_Conv-88        [-1, 128, 128, 128]               0\n",
      "          Up_Conv-89        [-1, 128, 128, 128]               0\n",
      "         Upsample-90        [-1, 128, 256, 256]               0\n",
      "           Conv2d-91         [-1, 64, 256, 256]           8,256\n",
      "           Conv2d-92         [-1, 64, 256, 256]          73,792\n",
      "         Conv_3_k-93         [-1, 64, 256, 256]               0\n",
      "      BatchNorm2d-94         [-1, 64, 256, 256]             128\n",
      "             ReLU-95         [-1, 64, 256, 256]               0\n",
      "           Conv2d-96         [-1, 64, 256, 256]          36,928\n",
      "         Conv_3_k-97         [-1, 64, 256, 256]               0\n",
      "      BatchNorm2d-98         [-1, 64, 256, 256]             128\n",
      "             ReLU-99         [-1, 64, 256, 256]               0\n",
      "     Double_Conv-100         [-1, 64, 256, 256]               0\n",
      "         Up_Conv-101         [-1, 64, 256, 256]               0\n",
      "          Conv2d-102          [-1, 2, 256, 256]             130\n",
      "================================================================\n",
      "Total params: 28,954,626\n",
      "Trainable params: 28,954,626\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 1384.00\n",
      "Params size (MB): 110.45\n",
      "Estimated Total Size (MB): 1495.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "# Utilizar torchsummary para obtener el resumen del modelo\n",
    "summary(model, (3, 256, 256))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_watnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
